{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataLoading example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install aac_datasets  # Uncomment if not installed !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import sys\n",
    "\n",
    "logging.basicConfig(\n",
    "    format=\"[%(asctime)s][%(name)s][%(levelname)s] - %(message)s\",\n",
    "    level=logging.WARNING,\n",
    "    stream=sys.stdout,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import aac_datasets\n",
    "import yaml\n",
    "\n",
    "from aac_datasets import Clotho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aac-datasets version: 0.4.0\n"
     ]
    }
   ],
   "source": [
    "print(f\"aac-datasets version: {aac_datasets.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Audio waveform shape: torch.Size([1, 1153825])\n",
      "Captions:\n",
      "- A muddled noise of broken channel of the TV\n",
      "- A television blares the rhythm of a static TV.\n",
      "- Loud television static dips in and out of focus\n",
      "- The loud buzz of static constantly changes pitch and volume.\n",
      "- heavy static and the beginnings of a signal on a transistor radio\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clotho_dev = Clotho(\".\", subset=\"dev\", download=True)\n",
    "\n",
    "example_0 = clotho_dev[0]\n",
    "audio_example = example_0[\"audio\"]\n",
    "captions_example = example_0[\"captions\"]\n",
    "\n",
    "print(f\"Audio waveform shape: {audio_example.shape}\")\n",
    "print(f\"Captions:\\n{yaml.dump(captions_example, sort_keys=False)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "from torch import Tensor\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "\n",
    "from aac_datasets import Clotho\n",
    "from aac_datasets.utils import AdvancedCollate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0 audio shape: torch.Size([4, 1, 1171305])\n",
      "Batch 0 captions:\n",
      "- - A muddled noise of broken channel of the TV\n",
      "  - A television blares the rhythm of a static TV.\n",
      "  - Loud television static dips in and out of focus\n",
      "  - The loud buzz of static constantly changes pitch and volume.\n",
      "  - heavy static and the beginnings of a signal on a transistor radio\n",
      "- - A person is turning a map over and over.\n",
      "  - A person is very carefully rapping a gift for someone else.\n",
      "  - A person is very carefully wrapping a gift for someone else.\n",
      "  - He sighed as he turned the pages of the book, stopping to scan the information.\n",
      "  - papers are being turned, stopped, then turned again and someone is breathing.\n",
      "- - Several barnyard animals mooing in a barn while it rains outside.\n",
      "  - The vocalization of several whales, along with the clicking of large numbers of\n",
      "    shrimp, reverberated below in the water.\n",
      "  - Underwater, large numbers of shrimp clicking and several whales vocalizing.\n",
      "  - Whales sing to one another over the flowing water in the distance.\n",
      "  - wales sing to one another with water flowing in the background\n",
      "- - An office chair is squeaking as someone bends back and forth in it.\n",
      "  - Popping and squeaking gradually tapers off to a low level.\n",
      "  - Someone is opening a creaky door slowly while a dog barks in the background\n",
      "  - Squeaking and popping followed by gradual popping and tapering off.\n",
      "  - an office chair is squeaking as someone leans forward and backward in it\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clotho_dev = Clotho(\".\", subset=\"dev\", download=False)\n",
    "\n",
    "# note: AdvancedCollate will pad audios files to max length to form a single tensor\n",
    "dataloader = DataLoader(clotho_dev, batch_size=4, collate_fn=AdvancedCollate({\"audio\": 0.0}))\n",
    "\n",
    "batch_0 = next(iter(dataloader))\n",
    "batch_0_audio: Tensor = batch_0[\"audio\"]\n",
    "batch_0_captions: list[list[str]] = batch_0[\"captions\"]\n",
    "\n",
    "print(f\"Batch 0 audio shape: {batch_0_audio.shape}\")\n",
    "print(f\"Batch 0 captions:\\n{yaml.dump(batch_0_captions, sort_keys=False)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_aac2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3d6a06574f445a0edc023bb3da185230ddb0852e3c5947b639b70cb3ab47eb74"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
