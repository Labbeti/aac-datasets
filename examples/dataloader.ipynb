{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataLoading example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install aac_datasets  # Uncomment if not installed !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import sys\n",
    "\n",
    "logging.basicConfig(\n",
    "    format=\"[%(asctime)s][%(name)s][%(levelname)s] - %(message)s\",\n",
    "    level=logging.WARNING,\n",
    "    stream=sys.stdout,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import aac_datasets\n",
    "import yaml\n",
    "\n",
    "from aac_datasets import Clotho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aac-datasets version: 0.6.1\n"
     ]
    }
   ],
   "source": [
    "print(f\"aac-datasets version: {aac_datasets.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Couldn't find appropriate backend to handle uri ./CLOTHO_v2.1/clotho_audio_files/development/Distorted AM Radio noise.wav and format None.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m clotho_dev = Clotho(\u001b[33m\"\u001b[39m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m, subset=\u001b[33m\"\u001b[39m\u001b[33mdev\u001b[39m\u001b[33m\"\u001b[39m, download=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m example_0 = \u001b[43mclotho_dev\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m      4\u001b[39m audio_example = example_0[\u001b[33m\"\u001b[39m\u001b[33maudio\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m      5\u001b[39m captions_example = example_0[\u001b[33m\"\u001b[39m\u001b[33mcaptions\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Audio_Captioning/aac-datasets/src/aac_datasets/datasets/base.py:438\u001b[39m, in \u001b[36mAACDataset.__getitem__\u001b[39m\u001b[34m(self, index)\u001b[39m\n\u001b[32m    435\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    436\u001b[39m     column = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m438\u001b[39m item = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_item\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumn\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[32m    440\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    441\u001b[39m     \u001b[38;5;28misinstance\u001b[39m(index, \u001b[38;5;28mint\u001b[39m)\n\u001b[32m    442\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._transform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    450\u001b[39m     )\n\u001b[32m    451\u001b[39m ):\n\u001b[32m    452\u001b[39m     item = \u001b[38;5;28mself\u001b[39m._transform(item)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Audio_Captioning/aac-datasets/src/aac_datasets/datasets/base.py:218\u001b[39m, in \u001b[36mAACDataset.get_item\u001b[39m\u001b[34m(self, index, column)\u001b[39m\n\u001b[32m    215\u001b[39m     column = \u001b[38;5;28mself\u001b[39m.column_names\n\u001b[32m    217\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(column, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(column, Iterable):\n\u001b[32m--> \u001b[39m\u001b[32m218\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m {column_i: \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_item\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumn_i\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m column_i \u001b[38;5;129;01min\u001b[39;00m column}\n\u001b[32m    220\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(index, (\u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mslice\u001b[39m)) \u001b[38;5;129;01mand\u001b[39;00m (\n\u001b[32m    221\u001b[39m     column \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._raw_data.keys() \u001b[38;5;129;01mand\u001b[39;00m column \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._online_fns\n\u001b[32m    222\u001b[39m ):\n\u001b[32m    223\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._raw_data[column][index]  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Audio_Captioning/aac-datasets/src/aac_datasets/datasets/base.py:256\u001b[39m, in \u001b[36mAACDataset.get_item\u001b[39m\u001b[34m(self, index, column)\u001b[39m\n\u001b[32m    251\u001b[39m     msg = (\n\u001b[32m    252\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mInvalid argument type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(index)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. (expected one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_INDEX_TYPES\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m)\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    253\u001b[39m     )\n\u001b[32m    254\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[32m--> \u001b[39m\u001b[32m256\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_load_online_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcolumn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Audio_Captioning/aac-datasets/src/aac_datasets/datasets/base.py:497\u001b[39m, in \u001b[36mAACDataset._load_online_value\u001b[39m\u001b[34m(self, column, index)\u001b[39m\n\u001b[32m    495\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m column \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._online_fns:\n\u001b[32m    496\u001b[39m     fn = \u001b[38;5;28mself\u001b[39m._online_fns[column]\n\u001b[32m--> \u001b[39m\u001b[32m497\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    498\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    499\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    500\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mInvalid argument column=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcolumn\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m at \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mindex\u001b[38;5;132;01m=}\u001b[39;00m\u001b[33m. (expected one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.all_columns\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m)\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    501\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Audio_Captioning/aac-datasets/src/aac_datasets/datasets/base.py:505\u001b[39m, in \u001b[36mAACDataset._load_audio\u001b[39m\u001b[34m(self, index)\u001b[39m\n\u001b[32m    503\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_load_audio\u001b[39m(\u001b[38;5;28mself\u001b[39m, index: \u001b[38;5;28mint\u001b[39m) -> Tensor:\n\u001b[32m    504\u001b[39m     fpath = \u001b[38;5;28mself\u001b[39m.get_item(index, \u001b[33m\"\u001b[39m\u001b[33mfpath\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m505\u001b[39m     audio_and_sr: Tuple[Tensor, \u001b[38;5;28mint\u001b[39m] = \u001b[43mtorchaudio\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfpath\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[32m    506\u001b[39m     audio, sr = audio_and_sr\n\u001b[32m    508\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m __debug__:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Audio_Captioning/aac-datasets/.venv/lib/python3.12/site-packages/torchaudio/_backend/utils.py:204\u001b[39m, in \u001b[36mget_load_func.<locals>.load\u001b[39m\u001b[34m(uri, frame_offset, num_frames, normalize, channels_first, format, buffer_size, backend)\u001b[39m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mload\u001b[39m(\n\u001b[32m    119\u001b[39m     uri: Union[BinaryIO, \u001b[38;5;28mstr\u001b[39m, os.PathLike],\n\u001b[32m    120\u001b[39m     frame_offset: \u001b[38;5;28mint\u001b[39m = \u001b[32m0\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    126\u001b[39m     backend: Optional[\u001b[38;5;28mstr\u001b[39m] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    127\u001b[39m ) -> Tuple[torch.Tensor, \u001b[38;5;28mint\u001b[39m]:\n\u001b[32m    128\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Load audio data from source.\u001b[39;00m\n\u001b[32m    129\u001b[39m \n\u001b[32m    130\u001b[39m \u001b[33;03m    By default (``normalize=True``, ``channels_first=True``), this function returns Tensor with\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    202\u001b[39m \u001b[33;03m            `[channel, time]` else `[time, channel]`.\u001b[39;00m\n\u001b[32m    203\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m204\u001b[39m     backend = \u001b[43mdispatcher\u001b[49m\u001b[43m(\u001b[49m\u001b[43muri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbackend\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    205\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m backend.load(uri, frame_offset, num_frames, normalize, channels_first, \u001b[38;5;28mformat\u001b[39m, buffer_size)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/Audio_Captioning/aac-datasets/.venv/lib/python3.12/site-packages/torchaudio/_backend/utils.py:116\u001b[39m, in \u001b[36mget_load_func.<locals>.dispatcher\u001b[39m\u001b[34m(uri, format, backend_name)\u001b[39m\n\u001b[32m    114\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m backend.can_decode(uri, \u001b[38;5;28mformat\u001b[39m):\n\u001b[32m    115\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m backend\n\u001b[32m--> \u001b[39m\u001b[32m116\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCouldn\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt find appropriate backend to handle uri \u001b[39m\u001b[38;5;132;01m{\u001b[39;00muri\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m and format \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mformat\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mRuntimeError\u001b[39m: Couldn't find appropriate backend to handle uri ./CLOTHO_v2.1/clotho_audio_files/development/Distorted AM Radio noise.wav and format None."
     ]
    }
   ],
   "source": [
    "clotho_dev = Clotho(\".\", subset=\"dev\", download=False)\n",
    "\n",
    "example_0 = clotho_dev[0]\n",
    "audio_example = example_0[\"audio\"]\n",
    "captions_example = example_0[\"captions\"]\n",
    "\n",
    "print(f\"Audio waveform shape: {audio_example.shape}\")\n",
    "print(f\"Captions:\\n{yaml.dump(captions_example, sort_keys=False)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "import yaml\n",
    "from torch import Tensor\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "\n",
    "from aac_datasets import Clotho\n",
    "from aac_datasets.utils.collate import AdvancedCollate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clotho_dev = Clotho(\".\", subset=\"dev\", download=False)\n",
    "\n",
    "# note: AdvancedCollate will pad audios files to max length to form a single tensor\n",
    "dataloader = DataLoader(\n",
    "    clotho_dev,\n",
    "    batch_size=4,\n",
    "    collate_fn=AdvancedCollate({\"audio\": 0.0}),\n",
    ")\n",
    "\n",
    "batch_0 = next(iter(dataloader))\n",
    "batch_0_audio: Tensor = batch_0[\"audio\"]\n",
    "batch_0_captions: List[List[str]] = batch_0[\"captions\"]\n",
    "\n",
    "print(f\"Batch 0 audio shape: {batch_0_audio.shape}\")\n",
    "print(f\"Batch 0 captions:\\n{yaml.dump(batch_0_captions, sort_keys=False)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aac-datasets",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
